#!/usr/bin/env python3
import argparse, subprocess, shutil, os, tqdm, glob
from collections import defaultdict
from pathlib import Path


_script_dir = Path( __file__ ).parent

def parse():
  parser = argparse.ArgumentParser(description='Analyze the coverage generated by inputs')
  parser.add_argument('--in', dest='input', help='input seed folder', required=True)
  parser.add_argument('--to', help='output folder', required=True)
  parser.add_argument('--source', help='source verilog file for better coverage names')
  parser.add_argument('--overwrite', help='overwrite the output directory', action='store_true')
  parser.add_argument('--skip-sim', help='skips the simulation and goes directly to the results analysis', action='store_true')
  args = parser.parse_args()
  return Path(args.input), Path(args.to), args.overwrite, args.skip_sim, args.source


_verilator_args = [
  '-O1', '-Wno-fatal', '-Wno-WIDTH', '-Wno-STMTDLY', '--prefix', 'Vtop', '--Mdir', 'verilated',
  '-cc', '-exe', 'verilator_conf.vlt', 'top.cpp', '--build', '--trace', '--coverage-user',
]

def build_sim():
  cmd = ['verilator'] + _verilator_args + ['TileAndMemTop.sv', 'SignalTracker.sv']
  subprocess.run(cmd, cwd=_script_dir, check=True)

def find_input_files(inp):
  assert os.path.isdir(inp)
  children = [os.path.join(inp, c) for c in os.listdir(inp)]
  files = [f for f in children if os.path.isfile(f)]
  return files

def create_output_dir(to, overwrite: bool):
  if os.path.exists(to):
    if overwrite:
      shutil.rmtree(to)
    else:
      raise RuntimeError(f"{to} already exists. Use `--overwrite` to allow it to be overwritten.")
  os.mkdir(to)

def run_sim(inp_file, to):
  assert os.path.exists(inp_file)
  binary = _script_dir / "verilated" / "Vtop"
  with open(inp_file, 'rb') as ff:
    subprocess.run([binary], cwd=to, check=True, stdin=ff)
  basename = os.path.basename(inp_file)
  shutil.move(to / "dump.vcd", to / (basename + ".vcd"))
  shutil.move(to / "coverage.dat", to / (basename + ".dat"))

def load_dat(filename: str):
  with open(filename, 'rb') as f:
    data = f.read()
  lines = [l[4:] for l in data.split(b"\n") if l.startswith(b"C '")]
  values = []
  for line in lines:
    dd, count = line.split(b"'")
    ees = {e[0].decode('ascii'): e[1].decode('ascii') for e in (e.split(b"\x02") for e in dd.split(b"\x01"))}
    ees['count'] = int(count.decode('ascii').strip())
    values.append(ees)
  return values

def load_combined_coverage(to, source):
  exprs = cover_names_from_source(source)
  counts = defaultdict(int)
  files = [to / f for f in glob.glob("*.dat", root_dir=to)]
  for ff in files:
    data = load_dat(ff)
    for ee in data:
      if ee['o'] != 'cover': continue
      line = int(ee['l'])
      if line in exprs:
        ident = exprs[line]
      else:
        ident = ee['h'] + ":" + ee['l']
      counts[ident] += ee['count']
  return dict(counts)

def analyze_coverage(to, source):
  counts = load_combined_coverage(to, source)
  not_covered = sorted([n for n,c in counts.items() if c == 0])
  print(f"Not covered ({len(not_covered)} / {len(counts)}):")
  print('\n'.join(not_covered))

_cover_start = "cover("
_cover_end = ");"

def cover_names_from_source(source):
  if source is None: return {}
  assert os.path.isfile(source), source
  mapping = {}
  with open(source) as ff:
    for ii, line in enumerate(ff.readlines()):
      line = line.strip()
      if line.startswith(_cover_start) and line.endswith(_cover_end):
        expr = line[len(_cover_start) : -len(_cover_end)].strip()
        mapping[ii+1] = expr
  return mapping


def main():
  inp, to, overwrite, skip_sim, source = parse()
  input_files = find_input_files(inp)
  if not skip_sim:
    create_output_dir(to, overwrite)
    build_sim()
    for ff in tqdm.tqdm(input_files):
      run_sim(ff, to)
  analyze_coverage(to, source)

if __name__ == "__main__":
  main()
